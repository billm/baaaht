// llm.proto - gRPC service definitions for LLM Gateway communication
//
// This file defines the LLMService which provides streaming LLM request handling,
// token tracking, and provider abstraction for agent communication.
//
// Copyright 2026 baaaht project

// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.6.1
// - protoc             v6.33.4
// source: proto/llm.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	emptypb "google.golang.org/protobuf/types/known/emptypb"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	LLMService_StreamLLM_FullMethodName       = "/llm.v1.LLMService/StreamLLM"
	LLMService_CompleteLLM_FullMethodName     = "/llm.v1.LLMService/CompleteLLM"
	LLMService_ListModels_FullMethodName      = "/llm.v1.LLMService/ListModels"
	LLMService_GetCapabilities_FullMethodName = "/llm.v1.LLMService/GetCapabilities"
	LLMService_HealthCheck_FullMethodName     = "/llm.v1.LLMService/HealthCheck"
	LLMService_GetStatus_FullMethodName       = "/llm.v1.LLMService/GetStatus"
)

// LLMServiceClient is the client API for LLMService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
//
// LLMService provides core LLM operations for agent communication
type LLMServiceClient interface {
	// StreamLLM establishes a bidirectional stream for LLM request/response handling
	StreamLLM(ctx context.Context, opts ...grpc.CallOption) (grpc.BidiStreamingClient[StreamLLMRequest, StreamLLMResponse], error)
	// CompleteLLM sends a non-streaming LLM request and receives a complete response
	CompleteLLM(ctx context.Context, in *CompleteLLMRequest, opts ...grpc.CallOption) (*CompleteLLMResponse, error)
	// ListModels lists all available models for the specified provider
	ListModels(ctx context.Context, in *ListModelsRequest, opts ...grpc.CallOption) (*ListModelsResponse, error)
	// GetCapabilities returns the capabilities of available LLM providers
	GetCapabilities(ctx context.Context, in *GetCapabilitiesRequest, opts ...grpc.CallOption) (*GetCapabilitiesResponse, error)
	// HealthCheck returns the health status of the LLM Gateway
	HealthCheck(ctx context.Context, in *emptypb.Empty, opts ...grpc.CallOption) (*LLMHealthCheckResponse, error)
	// GetStatus returns the current status of the LLM Gateway
	GetStatus(ctx context.Context, in *emptypb.Empty, opts ...grpc.CallOption) (*LLMStatusResponse, error)
}

type lLMServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewLLMServiceClient(cc grpc.ClientConnInterface) LLMServiceClient {
	return &lLMServiceClient{cc}
}

func (c *lLMServiceClient) StreamLLM(ctx context.Context, opts ...grpc.CallOption) (grpc.BidiStreamingClient[StreamLLMRequest, StreamLLMResponse], error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	stream, err := c.cc.NewStream(ctx, &LLMService_ServiceDesc.Streams[0], LLMService_StreamLLM_FullMethodName, cOpts...)
	if err != nil {
		return nil, err
	}
	x := &grpc.GenericClientStream[StreamLLMRequest, StreamLLMResponse]{ClientStream: stream}
	return x, nil
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type LLMService_StreamLLMClient = grpc.BidiStreamingClient[StreamLLMRequest, StreamLLMResponse]

func (c *lLMServiceClient) CompleteLLM(ctx context.Context, in *CompleteLLMRequest, opts ...grpc.CallOption) (*CompleteLLMResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(CompleteLLMResponse)
	err := c.cc.Invoke(ctx, LLMService_CompleteLLM_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *lLMServiceClient) ListModels(ctx context.Context, in *ListModelsRequest, opts ...grpc.CallOption) (*ListModelsResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ListModelsResponse)
	err := c.cc.Invoke(ctx, LLMService_ListModels_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *lLMServiceClient) GetCapabilities(ctx context.Context, in *GetCapabilitiesRequest, opts ...grpc.CallOption) (*GetCapabilitiesResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(GetCapabilitiesResponse)
	err := c.cc.Invoke(ctx, LLMService_GetCapabilities_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *lLMServiceClient) HealthCheck(ctx context.Context, in *emptypb.Empty, opts ...grpc.CallOption) (*LLMHealthCheckResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(LLMHealthCheckResponse)
	err := c.cc.Invoke(ctx, LLMService_HealthCheck_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *lLMServiceClient) GetStatus(ctx context.Context, in *emptypb.Empty, opts ...grpc.CallOption) (*LLMStatusResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(LLMStatusResponse)
	err := c.cc.Invoke(ctx, LLMService_GetStatus_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// LLMServiceServer is the server API for LLMService service.
// All implementations must embed UnimplementedLLMServiceServer
// for forward compatibility.
//
// LLMService provides core LLM operations for agent communication
type LLMServiceServer interface {
	// StreamLLM establishes a bidirectional stream for LLM request/response handling
	StreamLLM(grpc.BidiStreamingServer[StreamLLMRequest, StreamLLMResponse]) error
	// CompleteLLM sends a non-streaming LLM request and receives a complete response
	CompleteLLM(context.Context, *CompleteLLMRequest) (*CompleteLLMResponse, error)
	// ListModels lists all available models for the specified provider
	ListModels(context.Context, *ListModelsRequest) (*ListModelsResponse, error)
	// GetCapabilities returns the capabilities of available LLM providers
	GetCapabilities(context.Context, *GetCapabilitiesRequest) (*GetCapabilitiesResponse, error)
	// HealthCheck returns the health status of the LLM Gateway
	HealthCheck(context.Context, *emptypb.Empty) (*LLMHealthCheckResponse, error)
	// GetStatus returns the current status of the LLM Gateway
	GetStatus(context.Context, *emptypb.Empty) (*LLMStatusResponse, error)
	mustEmbedUnimplementedLLMServiceServer()
}

// UnimplementedLLMServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedLLMServiceServer struct{}

func (UnimplementedLLMServiceServer) StreamLLM(grpc.BidiStreamingServer[StreamLLMRequest, StreamLLMResponse]) error {
	return status.Error(codes.Unimplemented, "method StreamLLM not implemented")
}
func (UnimplementedLLMServiceServer) CompleteLLM(context.Context, *CompleteLLMRequest) (*CompleteLLMResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method CompleteLLM not implemented")
}
func (UnimplementedLLMServiceServer) ListModels(context.Context, *ListModelsRequest) (*ListModelsResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method ListModels not implemented")
}
func (UnimplementedLLMServiceServer) GetCapabilities(context.Context, *GetCapabilitiesRequest) (*GetCapabilitiesResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method GetCapabilities not implemented")
}
func (UnimplementedLLMServiceServer) HealthCheck(context.Context, *emptypb.Empty) (*LLMHealthCheckResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method HealthCheck not implemented")
}
func (UnimplementedLLMServiceServer) GetStatus(context.Context, *emptypb.Empty) (*LLMStatusResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method GetStatus not implemented")
}
func (UnimplementedLLMServiceServer) mustEmbedUnimplementedLLMServiceServer() {}
func (UnimplementedLLMServiceServer) testEmbeddedByValue()                    {}

// UnsafeLLMServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to LLMServiceServer will
// result in compilation errors.
type UnsafeLLMServiceServer interface {
	mustEmbedUnimplementedLLMServiceServer()
}

func RegisterLLMServiceServer(s grpc.ServiceRegistrar, srv LLMServiceServer) {
	// If the following call panics, it indicates UnimplementedLLMServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&LLMService_ServiceDesc, srv)
}

func _LLMService_StreamLLM_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(LLMServiceServer).StreamLLM(&grpc.GenericServerStream[StreamLLMRequest, StreamLLMResponse]{ServerStream: stream})
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type LLMService_StreamLLMServer = grpc.BidiStreamingServer[StreamLLMRequest, StreamLLMResponse]

func _LLMService_CompleteLLM_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CompleteLLMRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LLMServiceServer).CompleteLLM(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LLMService_CompleteLLM_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LLMServiceServer).CompleteLLM(ctx, req.(*CompleteLLMRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _LLMService_ListModels_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ListModelsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LLMServiceServer).ListModels(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LLMService_ListModels_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LLMServiceServer).ListModels(ctx, req.(*ListModelsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _LLMService_GetCapabilities_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetCapabilitiesRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LLMServiceServer).GetCapabilities(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LLMService_GetCapabilities_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LLMServiceServer).GetCapabilities(ctx, req.(*GetCapabilitiesRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _LLMService_HealthCheck_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(emptypb.Empty)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LLMServiceServer).HealthCheck(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LLMService_HealthCheck_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LLMServiceServer).HealthCheck(ctx, req.(*emptypb.Empty))
	}
	return interceptor(ctx, in, info, handler)
}

func _LLMService_GetStatus_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(emptypb.Empty)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(LLMServiceServer).GetStatus(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: LLMService_GetStatus_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(LLMServiceServer).GetStatus(ctx, req.(*emptypb.Empty))
	}
	return interceptor(ctx, in, info, handler)
}

// LLMService_ServiceDesc is the grpc.ServiceDesc for LLMService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var LLMService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "llm.v1.LLMService",
	HandlerType: (*LLMServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CompleteLLM",
			Handler:    _LLMService_CompleteLLM_Handler,
		},
		{
			MethodName: "ListModels",
			Handler:    _LLMService_ListModels_Handler,
		},
		{
			MethodName: "GetCapabilities",
			Handler:    _LLMService_GetCapabilities_Handler,
		},
		{
			MethodName: "HealthCheck",
			Handler:    _LLMService_HealthCheck_Handler,
		},
		{
			MethodName: "GetStatus",
			Handler:    _LLMService_GetStatus_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamLLM",
			Handler:       _LLMService_StreamLLM_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "proto/llm.proto",
}
